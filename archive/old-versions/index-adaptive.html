<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Adaptive Realtime Conference</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            min-height: 100vh;
            padding: 20px;
        }
        .container { max-width: 1400px; margin: 0 auto; }
        h1 { text-align: center; margin-bottom: 20px; font-size: 24px; }
        .status {
            text-align: center;
            padding: 10px;
            background: rgba(255,255,255,0.2);
            border-radius: 10px;
            margin-bottom: 20px;
            font-size: 14px;
        }
        .videos {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }
        .video-container {
            background: rgba(0,0,0,0.3);
            border-radius: 10px;
            padding: 10px;
            position: relative;
        }
        .video-label {
            position: absolute;
            top: 15px;
            left: 15px;
            background: rgba(0,0,0,0.7);
            padding: 5px 10px;
            border-radius: 5px;
            z-index: 10;
            font-size: 12px;
        }
        .quality-indicator {
            position: absolute;
            top: 15px;
            right: 15px;
            background: rgba(0,0,0,0.7);
            padding: 5px 10px;
            border-radius: 5px;
            z-index: 10;
            font-size: 10px;
        }
        video, canvas {
            width: 100%;
            height: auto;
            min-height: 200px;
            border-radius: 8px;
            background: #000;
            display: block;
        }
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
            gap: 10px;
            padding: 15px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
            margin-top: 20px;
        }
        .stat {
            text-align: center;
        }
        .stat-label {
            font-size: 11px;
            opacity: 0.8;
            margin-bottom: 3px;
        }
        .stat-value {
            font-size: 18px;
            font-weight: bold;
        }
        .controls {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin-top: 20px;
        }
        button {
            padding: 8px 20px;
            font-size: 14px;
            border: none;
            border-radius: 6px;
            background: white;
            color: #764ba2;
            cursor: pointer;
            font-weight: bold;
        }
        button:hover { transform: scale(1.05); }
        .audio-indicator {
            position: absolute;
            bottom: 15px;
            left: 15px;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            background: rgba(0, 255, 0, 0.5);
            animation: pulse 1s infinite;
            display: none;
        }
        .audio-indicator.active {
            display: block;
        }
        @keyframes pulse {
            0% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.2); opacity: 0.7; }
            100% { transform: scale(1); opacity: 1; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¥ Adaptive Realtime Conference</h1>
        <div class="status" id="status">Initializing...</div>
        
        <div class="videos" id="videos"></div>
        
        <div class="stats">
            <div class="stat">
                <div class="stat-label">Latency</div>
                <div class="stat-value" id="latency">0ms</div>
            </div>
            <div class="stat">
                <div class="stat-label">Audio Buffer</div>
                <div class="stat-value" id="audioBuffer">0ms</div>
            </div>
            <div class="stat">
                <div class="stat-label">Video FPS</div>
                <div class="stat-value" id="fps">0</div>
            </div>
            <div class="stat">
                <div class="stat-label">Quality</div>
                <div class="stat-value" id="quality">-</div>
            </div>
            <div class="stat">
                <div class="stat-label">Dropped</div>
                <div class="stat-value" id="dropped">0</div>
            </div>
            <div class="stat">
                <div class="stat-label">Network</div>
                <div class="stat-value" id="network">0kb/s</div>
            </div>
        </div>
        
        <div class="controls">
            <button id="muteBtn" onclick="toggleAudio()">ðŸ”‡ Mute</button>
            <button id="videoBtn" onclick="toggleVideo()">ðŸ“¹ Stop Video</button>
        </div>
    </div>

    <script>
        // Configuration for adaptive streaming
        const WS_URL = window.location.protocol === 'https:' ? 
            'wss://194.87.103.57.nip.io/ws' : 'ws://194.87.103.57:3001/ws';
        
        // Adaptive quality levels
        const QUALITY_LEVELS = [
            { name: 'ultra-low', width: 160, height: 120, fps: 10, jpeg: 0.3, audioBitrate: 16000 },
            { name: 'low', width: 320, height: 240, fps: 15, jpeg: 0.4, audioBitrate: 24000 },
            { name: 'medium', width: 640, height: 480, fps: 20, jpeg: 0.5, audioBitrate: 32000 },
            { name: 'high', width: 960, height: 720, fps: 25, jpeg: 0.6, audioBitrate: 48000 },
            { name: 'ultra', width: 1280, height: 960, fps: 30, jpeg: 0.7, audioBitrate: 64000 }
        ];
        
        // State
        let ws = null;
        let localStream = null;
        let myId = null;
        let audioEnabled = true;
        let videoEnabled = true;
        let currentQualityIndex = 2; // Start with medium
        let participants = new Map();
        
        // Audio state - completely decoupled
        let audioContext = null;
        let audioProcessor = null;
        let audioDestination = null;
        
        // Video state - separate pipeline
        let videoCanvas = null;
        let videoCtx = null;
        let videoAnimationId = null;
        
        // Performance monitoring
        let stats = {
            framesSent: 0,
            framesDropped: 0,
            audioPacketsSent: 0,
            lastFrameTime: 0,
            latencyMs: 0,
            audioBufferMs: 0,
            networkKbps: 0,
            clientAckTimes: new Map(),
            recentLatencies: [],
            targetFps: 20,
            actualFps: 0
        };
        
        // Feedback loop state
        let feedbackInterval = null;
        let qualityAdjustmentInterval = null;
        
        class AdaptiveAudioProcessor {
            constructor(stream) {
                this.stream = stream;
                this.context = new (window.AudioContext || window.webkitAudioContext)({ 
                    sampleRate: 48000,
                    latencyHint: 'interactive'
                });
                this.chunks = [];
                this.sendInterval = null;
            }
            
            async start() {
                const source = this.context.createMediaStreamSource(this.stream);
                
                // Use ScriptProcessor for compatibility (will migrate to AudioWorklet later)
                this.processor = this.context.createScriptProcessor(512, 1, 1);
                
                this.processor.onaudioprocess = (e) => {
                    if (!audioEnabled) return;
                    
                    const inputData = e.inputBuffer.getChannelData(0);
                    const pcmData = new Float32Array(inputData);
                    this.chunks.push(pcmData);
                };
                
                source.connect(this.processor);
                this.processor.connect(this.context.destination);
                
                // Send audio chunks at high frequency (every 20ms for low latency)
                this.sendInterval = setInterval(() => this.sendAudioChunks(), 20);
            }
            
            sendAudioChunks() {
                if (this.chunks.length === 0 || !ws || ws.readyState !== WebSocket.OPEN) return;
                
                // Combine chunks
                const totalLength = this.chunks.reduce((sum, chunk) => sum + chunk.length, 0);
                const combined = new Float32Array(totalLength);
                let offset = 0;
                for (const chunk of this.chunks) {
                    combined.set(chunk, offset);
                    offset += chunk.length;
                }
                this.chunks = [];
                
                // Convert to 16-bit PCM for transmission
                const pcm16 = new Int16Array(combined.length);
                for (let i = 0; i < combined.length; i++) {
                    pcm16[i] = Math.max(-32768, Math.min(32767, combined[i] * 32768));
                }
                
                // Send with timestamp for latency tracking
                const audioData = {
                    type: 'audio-chunk',
                    data: btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer))),
                    timestamp: Date.now(),
                    sampleRate: this.context.sampleRate,
                    seq: stats.audioPacketsSent++
                };
                
                ws.send(JSON.stringify(audioData));
            }
            
            stop() {
                if (this.sendInterval) {
                    clearInterval(this.sendInterval);
                }
                if (this.processor) {
                    this.processor.disconnect();
                }
                if (this.context) {
                    this.context.close();
                }
            }
        }
        
        class AdaptiveVideoCapture {
            constructor(stream) {
                this.stream = stream;
                this.video = document.createElement('video');
                this.video.srcObject = stream;
                this.video.play();
                
                this.canvas = document.createElement('canvas');
                this.ctx = this.canvas.getContext('2d');
                
                this.lastFrameTime = 0;
                this.frameInterval = 1000 / QUALITY_LEVELS[currentQualityIndex].fps;
            }
            
            start() {
                this.captureFrame();
            }
            
            captureFrame = () => {
                if (!videoEnabled) {
                    videoAnimationId = requestAnimationFrame(this.captureFrame);
                    return;
                }
                
                const now = Date.now();
                const timeSinceLastFrame = now - this.lastFrameTime;
                
                // Adaptive frame dropping
                if (timeSinceLastFrame < this.frameInterval) {
                    videoAnimationId = requestAnimationFrame(this.captureFrame);
                    return;
                }
                
                // Check if we should drop this frame based on latency
                if (stats.latencyMs > 500 && timeSinceLastFrame < this.frameInterval * 2) {
                    stats.framesDropped++;
                    videoAnimationId = requestAnimationFrame(this.captureFrame);
                    return;
                }
                
                const quality = QUALITY_LEVELS[currentQualityIndex];
                this.canvas.width = quality.width;
                this.canvas.height = quality.height;
                
                this.ctx.drawImage(this.video, 0, 0, quality.width, quality.height);
                
                this.canvas.toBlob((blob) => {
                    if (!blob || !ws || ws.readyState !== WebSocket.OPEN) return;
                    
                    const reader = new FileReader();
                    reader.onloadend = () => {
                        const frameData = {
                            type: 'video-frame',
                            data: reader.result.split(',')[1],
                            timestamp: Date.now(),
                            seq: stats.framesSent++,
                            quality: quality.name,
                            expectAck: stats.framesSent % 10 === 0 // Request ack every 10th frame
                        };
                        
                        ws.send(JSON.stringify(frameData));
                        this.lastFrameTime = now;
                        
                        // Track for latency measurement
                        if (frameData.expectAck) {
                            stats.clientAckTimes.set(frameData.seq, frameData.timestamp);
                        }
                    };
                    reader.readAsDataURL(blob);
                }, 'image/jpeg', quality.jpeg);
                
                videoAnimationId = requestAnimationFrame(this.captureFrame);
            };
            
            stop() {
                if (videoAnimationId) {
                    cancelAnimationFrame(videoAnimationId);
                }
            }
            
            updateQuality(index) {
                const quality = QUALITY_LEVELS[index];
                this.frameInterval = 1000 / quality.fps;
                
                // Update video track constraints
                const videoTrack = this.stream.getVideoTracks()[0];
                if (videoTrack) {
                    videoTrack.applyConstraints({
                        width: quality.width,
                        height: quality.height,
                        frameRate: quality.fps
                    });
                }
            }
        }
        
        class RealtimeAudioPlayer {
            constructor() {
                this.context = new (window.AudioContext || window.webkitAudioContext)();
                this.queue = [];
                this.isPlaying = false;
                this.minBufferSize = 2; // Minimal buffer for ultra-low latency
                this.maxBufferSize = 5;
            }
            
            addChunk(base64Data, sampleRate) {
                const binaryString = atob(base64Data);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                for (let i = 0; i < len; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                const pcm16 = new Int16Array(bytes.buffer);
                const float32 = new Float32Array(pcm16.length);
                for (let i = 0; i < pcm16.length; i++) {
                    float32[i] = pcm16[i] / 32768;
                }
                
                this.queue.push({ data: float32, sampleRate });
                
                // Adaptive buffer management - drop old chunks if buffer grows too large
                if (this.queue.length > this.maxBufferSize) {
                    const toDrop = this.queue.length - this.maxBufferSize;
                    this.queue.splice(0, toDrop);
                    console.log(`Dropped ${toDrop} audio chunks to maintain realtime`);
                }
                
                if (!this.isPlaying && this.queue.length >= this.minBufferSize) {
                    this.playNext();
                }
                
                stats.audioBufferMs = (this.queue.length * 20); // Approximate ms in buffer
            }
            
            playNext() {
                if (this.queue.length === 0) {
                    this.isPlaying = false;
                    return;
                }
                
                this.isPlaying = true;
                const chunk = this.queue.shift();
                
                const buffer = this.context.createBuffer(1, chunk.data.length, chunk.sampleRate || 48000);
                buffer.getChannelData(0).set(chunk.data);
                
                const source = this.context.createBufferSource();
                source.buffer = buffer;
                source.connect(this.context.destination);
                
                source.onended = () => this.playNext();
                source.start(0);
            }
        }
        
        // Participant management
        function addVideoElement(id, label, isLocal = false) {
            if (document.getElementById(`video-${id}`)) return;
            
            const container = document.createElement('div');
            container.className = 'video-container';
            container.id = `container-${id}`;
            
            container.innerHTML = `
                <div class="video-label">${label}</div>
                <div class="quality-indicator" id="quality-${id}">-</div>
                ${isLocal ? '<video id="video-' + id + '" autoplay muted></video>' : 
                           '<canvas id="video-' + id + '"></canvas>'}
                <div class="audio-indicator" id="audio-${id}"></div>
            `;
            
            document.getElementById('videos').appendChild(container);
            
            if (!isLocal) {
                participants.set(id, {
                    audioPlayer: new RealtimeAudioPlayer(),
                    lastVideoFrame: Date.now(),
                    framesReceived: 0
                });
            }
        }
        
        // WebSocket connection
        async function connect() {
            try {
                // Get user media
                localStream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        frameRate: { ideal: 30 }
                    },
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 48000
                    }
                });
                
                // Setup local video
                addVideoElement('local', 'You', true);
                document.getElementById('video-local').srcObject = localStream;
                
                // Initialize audio and video processors
                const audioProcessor = new AdaptiveAudioProcessor(localStream);
                await audioProcessor.start();
                
                const videoCapture = new AdaptiveVideoCapture(localStream);
                
                // Connect WebSocket
                ws = new WebSocket(WS_URL);
                
                ws.onopen = () => {
                    console.log('Connected to server');
                    myId = 'user-' + Math.random().toString(36).substr(2, 9);
                    
                    ws.send(JSON.stringify({
                        type: 'join',
                        id: myId,
                        room: 'main'
                    }));
                    
                    // Start video capture after connection
                    videoCapture.start();
                    
                    // Start feedback loop
                    startFeedbackLoop();
                    startQualityAdjustment();
                    
                    document.getElementById('status').textContent = 'Connected - Room: main';
                };
                
                ws.onmessage = (event) => {
                    const msg = JSON.parse(event.data);
                    handleMessage(msg);
                };
                
                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    document.getElementById('status').textContent = 'Connection error';
                };
                
                ws.onclose = () => {
                    console.log('Disconnected');
                    document.getElementById('status').textContent = 'Disconnected';
                    stopFeedbackLoop();
                    stopQualityAdjustment();
                };
                
                // Store processors for cleanup
                window.audioProcessor = audioProcessor;
                window.videoCapture = videoCapture;
                
            } catch (error) {
                console.error('Setup error:', error);
                document.getElementById('status').textContent = 'Setup failed: ' + error.message;
            }
        }
        
        function handleMessage(msg) {
            switch (msg.type) {
                case 'welcome':
                    myId = msg.yourId;
                    msg.participants.forEach(id => {
                        addVideoElement(id, `User ${id.slice(-4)}`, false);
                    });
                    break;
                    
                case 'participant-joined':
                    addVideoElement(msg.participantId, `User ${msg.participantId.slice(-4)}`, false);
                    break;
                    
                case 'participant-left':
                    const container = document.getElementById(`container-${msg.participantId}`);
                    if (container) container.remove();
                    participants.delete(msg.participantId);
                    break;
                    
                case 'audio-chunk':
                    const participant = participants.get(msg.from);
                    if (participant) {
                        participant.audioPlayer.addChunk(msg.data, msg.sampleRate);
                        
                        // Show audio indicator
                        const indicator = document.getElementById(`audio-${msg.from}`);
                        if (indicator) {
                            indicator.classList.add('active');
                            setTimeout(() => indicator.classList.remove('active'), 100);
                        }
                    }
                    break;
                    
                case 'video-frame':
                    handleVideoFrame(msg);
                    break;
                    
                case 'frame-ack':
                    handleFrameAck(msg);
                    break;
                    
                case 'client-stats':
                    handleClientStats(msg);
                    break;
            }
        }
        
        function handleVideoFrame(msg) {
            const canvas = document.getElementById(`video-${msg.from}`);
            if (!canvas) return;
            
            const participant = participants.get(msg.from);
            if (!participant) return;
            
            participant.framesReceived++;
            participant.lastVideoFrame = Date.now();
            
            // Decode and display frame
            const img = new Image();
            img.onload = () => {
                const ctx = canvas.getContext('2d');
                canvas.width = img.width;
                canvas.height = img.height;
                ctx.drawImage(img, 0, 0);
                
                // Update quality indicator
                const qualityEl = document.getElementById(`quality-${msg.from}`);
                if (qualityEl) {
                    qualityEl.textContent = `${msg.quality || 'unknown'} ${img.width}x${img.height}`;
                }
            };
            img.src = 'data:image/jpeg;base64,' + msg.data;
            
            // Send ack if requested
            if (msg.expectAck && ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                    type: 'frame-ack',
                    from: myId,
                    to: msg.from,
                    seq: msg.seq,
                    timestamp: Date.now()
                }));
            }
        }
        
        function handleFrameAck(msg) {
            if (msg.to !== myId) return;
            
            const sentTime = stats.clientAckTimes.get(msg.seq);
            if (sentTime) {
                const latency = Date.now() - sentTime;
                stats.recentLatencies.push(latency);
                
                // Keep only recent latencies
                if (stats.recentLatencies.length > 10) {
                    stats.recentLatencies.shift();
                }
                
                // Calculate average latency
                stats.latencyMs = Math.round(
                    stats.recentLatencies.reduce((a, b) => a + b, 0) / stats.recentLatencies.length
                );
                
                stats.clientAckTimes.delete(msg.seq);
                
                // Clean old entries
                if (stats.clientAckTimes.size > 20) {
                    const oldestKey = stats.clientAckTimes.keys().next().value;
                    stats.clientAckTimes.delete(oldestKey);
                }
            }
        }
        
        function handleClientStats(msg) {
            // Process client feedback for quality adjustment
            if (msg.from && msg.bufferHealth !== undefined) {
                // Adjust quality based on client buffer health
                if (msg.bufferHealth < 0.3 && currentQualityIndex > 0) {
                    adjustQuality(-1);
                } else if (msg.bufferHealth > 0.8 && currentQualityIndex < QUALITY_LEVELS.length - 1) {
                    adjustQuality(1);
                }
            }
        }
        
        function startFeedbackLoop() {
            feedbackInterval = setInterval(() => {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    // Send our stats to server
                    ws.send(JSON.stringify({
                        type: 'client-stats',
                        from: myId,
                        latency: stats.latencyMs,
                        audioBuffer: stats.audioBufferMs,
                        fps: stats.actualFps,
                        quality: QUALITY_LEVELS[currentQualityIndex].name,
                        dropped: stats.framesDropped
                    }));
                }
                
                updateStatsDisplay();
            }, 1000);
        }
        
        function stopFeedbackLoop() {
            if (feedbackInterval) {
                clearInterval(feedbackInterval);
            }
        }
        
        function startQualityAdjustment() {
            qualityAdjustmentInterval = setInterval(() => {
                // Auto-adjust quality based on latency
                if (stats.latencyMs > 800) {
                    // High latency - reduce quality
                    adjustQuality(-1);
                } else if (stats.latencyMs < 200 && stats.framesDropped === 0) {
                    // Low latency and no drops - can increase quality
                    adjustQuality(1);
                }
                
                // Reset frame drop counter
                stats.framesDropped = 0;
            }, 5000);
        }
        
        function stopQualityAdjustment() {
            if (qualityAdjustmentInterval) {
                clearInterval(qualityAdjustmentInterval);
            }
        }
        
        function adjustQuality(direction) {
            const newIndex = Math.max(0, Math.min(QUALITY_LEVELS.length - 1, currentQualityIndex + direction));
            if (newIndex !== currentQualityIndex) {
                currentQualityIndex = newIndex;
                
                if (window.videoCapture) {
                    window.videoCapture.updateQuality(currentQualityIndex);
                }
                
                console.log(`Quality adjusted to: ${QUALITY_LEVELS[currentQualityIndex].name}`);
            }
        }
        
        function updateStatsDisplay() {
            // Calculate actual FPS
            const quality = QUALITY_LEVELS[currentQualityIndex];
            stats.actualFps = Math.min(quality.fps, Math.round(1000 / (stats.latencyMs / 10 || 100)));
            
            document.getElementById('latency').textContent = stats.latencyMs + 'ms';
            document.getElementById('audioBuffer').textContent = stats.audioBufferMs + 'ms';
            document.getElementById('fps').textContent = stats.actualFps;
            document.getElementById('quality').textContent = quality.name;
            document.getElementById('dropped').textContent = stats.framesDropped;
            document.getElementById('network').textContent = Math.round(stats.networkKbps) + 'kb/s';
        }
        
        function toggleAudio() {
            audioEnabled = !audioEnabled;
            const btn = document.getElementById('muteBtn');
            btn.textContent = audioEnabled ? 'ðŸ”‡ Mute' : 'ðŸ”Š Unmute';
            
            if (localStream) {
                localStream.getAudioTracks().forEach(track => {
                    track.enabled = audioEnabled;
                });
            }
        }
        
        function toggleVideo() {
            videoEnabled = !videoEnabled;
            const btn = document.getElementById('videoBtn');
            btn.textContent = videoEnabled ? 'ðŸ“¹ Stop Video' : 'ðŸ“¹ Start Video';
            
            if (localStream) {
                localStream.getVideoTracks().forEach(track => {
                    track.enabled = videoEnabled;
                });
            }
        }
        
        // Auto-start on load
        window.addEventListener('load', () => {
            setTimeout(connect, 500);
        });
        
        // Cleanup on unload
        window.addEventListener('beforeunload', () => {
            if (ws) ws.close();
            if (window.audioProcessor) window.audioProcessor.stop();
            if (window.videoCapture) window.videoCapture.stop();
            if (localStream) {
                localStream.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>